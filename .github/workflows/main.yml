---
name: main

on:
  create:
    tags:  # any tag regardless of its name, no branches
      - "**"
  push:
    branches:  # any integration branch but not tag
      - "*"

jobs:
  validate_code:
    name: ${{ matrix.name }}
    runs-on: ubuntu-20.04
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: ansible-lint
            command: yamllint --strict .

          - name: vagrant validate
            command: |
              export VAGRANT_VERSION
              sudo -E bash -c "${PWD}/tests/scripts/vagrant-validate.sh"
              echo done

          # - name: markdown lint

          # - name: and other stuffs...
    env:
      VAGRANT_VERSION: 2.2.10
      KUBESPRAY_VERSION: v2.14.1
      ANSIBLE_FORCE_COLOR: "true"
      SSH_USER: root
      MITOGEN_ENABLE: "false"
      ANSIBLE_LOG_LEVEL: "-vv"
    steps:
      - name: Check out code
        uses: actions/checkout@v2

      - name: Install a default Python
        uses: actions/setup-python@v2

      - name: Install dependencies
        run: |
          echo do some python -m pip install if needed

      - name: Rebase
        run: |
          # No CI_COMMIT_REF_NAME => find a way to get it ? ./tests/scripts/rebase.sh

      - name: Create ssh directory
        run: |
          sudo mkdir -p /.ssh

      - name: Install requirements
        run: |
          python -m pip install -r tests/requirements.txt
        # TODO : when requirements wanted

      - name: Run command
        run: |
          ${{ matrix.command }}

  build:
    name: ${{ matrix.name }}
    runs-on: ubuntu-20.04
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: kubevirt centos 7 calico

          - name: kubevirt ubuntu 18
    env:
      KUBESPRAY_VERSION: v2.14.1
      ANSIBLE_FORCE_COLOR: "true"
      SSH_USER: root
      MITOGEN_ENABLE: "false"
      ANSIBLE_LOG_LEVEL: "-vv"

    steps:
      - name: Check out code
        uses: actions/checkout@v2

      - name: Install a default Python
        uses: actions/setup-python@v2
        if: ${{ ! contains(matrix.tox_env, 'py') }}

      - name: Install dependencies
        run: |
          python -m pip install -U pip
          pip install tox
        if: ${{ ! contains(matrix.tox_env, 'py') }}

      - name: Run tox -e ${{ matrix.tox_env }}
        run: |
          echo "${{ matrix.PREFIX }} tox -e ${{ matrix.tox_env }}"
          ${{ matrix.PREFIX }} tox -e ${{ matrix.tox_env }}
        if: ${{ ! contains(matrix.tox_env, 'py') }}

      - name: Enable ipv4 and ipv6 forwarding
        run: |
          sudo sysctl -w net.ipv6.conf.all.forwarding=1
          sudo sysctl -w net.ipv4.ip_forward=1


      # TODO : split
      - name: Install docker
        run: |
          . /etc/os-release
          ## FIXME Workaround for https://github.com/kubernetes/kubernetes/issues/61058
          ### And https://github.com/LiliC/travis-minikube/blob/e0f26f7b388057f51a0e2558afd5f990e07b6c49/.travis.yml#L11
          sudo mount --make-rshared /
          ### conntrack is required by kube 1.18
          sudo apt-get update
          sudo apt-get install -y conntrack
          # sudo systemctl stop apparmor
          curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -
          sudo add-apt-repository "deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable"
          sudo apt-get update
          sudo apt-get -y -o Dpkg::Options::="--force-confnew" install docker-ce
          sudo apt install -y qemu qemu-kvm libvirt-daemon libvirt-clients bridge-utils virt-manager libvirt-daemon-system dnsmasq
          sudo systemctl restart libvirtd
          # Install network
          sudo mkdir -p /etc/cni/net.d
          # curl -qsSL https://raw.githubusercontent.com/containers/libpod/master/cni/87-podman-bridge.conflist | sudo tee /etc/cni/net.d/87-podman-bridge.conf
          curl -qsSL https://github.com/containernetworking/plugins/releases/download/v0.8.6/cni-plugins-linux-amd64-v0.8.6.tgz --output /tmp/cni.tgz
          sudo mkdir -p /usr/libexec/cni
          sudo tar -C /usr/libexec/cni -xvzf /tmp/cni.tgz


      - name: Tweak Ubuntu apparmor
        run: |
          sudo cat /etc/apparmor.d/usr.sbin.libvirtd
          tweak_qemu_apprarmor="$(head -n -1 /etc/apparmor.d/usr.sbin.libvirtd; echo "  /usr/libexec/qemu-kvm rmix,"; tail -1 /etc/apparmor.d/usr.sbin.libvirtd)"
          echo "$tweak_qemu_apprarmor"
          echo "$tweak_qemu_apprarmor" | sudo dd of=/etc/apparmor.d/usr.sbin.libvirtd
          sudo cat /etc/apparmor.d/usr.sbin.libvirtd
          sudo systemctl reload apparmor.service


      - name: Install kubectl
        run: |
          curl -LO https://storage.googleapis.com/kubernetes-release/release/${{ matrix.KUBERNETES_VERSION }}/bin/linux/amd64/kubectl; chmod +x ./kubectl
          sudo install kubectl /usr/local/bin


      - name: Install kind
        run: |
          curl -Lo ./kind "https://kind.sigs.k8s.io/dl/v0.9.0/kind-$(uname)-amd64" && chmod +x ./kind
          sudo install kind /usr/local/bin


      - name: Create single node cluster
        run: |
          cat <<EOF | sudo kind create cluster -v7 --wait 1m --retain --config=-
          kind: Cluster
          apiVersion: kind.x-k8s.io/v1alpha4
          networking:
            ipFamily: ipv4
          EOF


      - name: Wait and get Cluster status
        run: |
          # wait network is ready
          sudo kubectl wait --for=condition=ready pods --namespace=kube-system -l k8s-app=kube-dns
          sudo kubectl get nodes -o wide
          sudo kubectl get pods -A


      - name: Install kubevirt
        run: |
          sudo kubectl create -f https://github.com/kubevirt/kubevirt/releases/download/v0.36.0/kubevirt-operator.yaml
          sudo kubectl create configmap kubevirt-config -n kubevirt --from-literal debug.useEmulation=true
          sudo kubectl create -f https://github.com/kubevirt/kubevirt/releases/download/v0.36.0/kubevirt-cr.yaml


      - name: Install virtcl
        run: |
          export ARCH=linux-amd64
          curl -L -o virtctl https://github.com/jseguillon/kubevirt/releases/download/9.9.0/virtctl-v0.37.0-rc.0-72-g246eb6f22-linux-amd64
          chmod +x virtctl
          sudo install virtctl /usr/local/bin


      # - name: Build kubespray container
      #   run: |
      #     docker build --build-arg PYTHON_BASE_IMAGE=${{ matrix.PYTHON_BASE_IMAGE }} --build-arg KUBERNETES_VERSION=${{ matrix.KUBERNETES_VERSION }} . --file tools/Dockerfile  -t molecule_kubevirt_${{ matrix.tox_env }}:latest
      #     # FIXME : load is slow : set a private registry, as described here https://kind.sigs.k8s.io/docs/user/local-registry/
      #     sudo kind load docker-image molecule_kubevirt_${{ matrix.tox_env }}:latest


      # - name: Push kubespray image to Kind
      #   run: |
      #     sudo kind load docker-image molecule_kubevirt_${{ matrix.tox_env }}:latest


      - name: Install kail
        run: |
          curl -SL https://github.com/boz/kail/releases/download/v0.15.0/kail_0.15.0_linux_amd64.tar.gz -o kail.tar.gz
          tar xf kail.tar.gz
          sudo install kail /usr/local/bin


      - name: Wait and get Kubevirt status
        run: |
          # wait network is ready
          sudo kubectl wait --for=condition=ready pods --namespace=kubevirt -l kubevirt.io=virt-operator
          sudo kubectl wait --for=condition=ready pods --namespace=kubevirt -l kubevirt.io=virt-api || true
          sudo kubectl wait --for=condition=ready pods --namespace=kubevirt -l kubevirt.io=virt-controller || true
          sudo kubectl wait --for=condition=ready pods --namespace=kubevirt -l kubevirt.io=virt-handler || true
          sudo kubectl get nodes -o wide
          sudo kubectl get pods -A


      # - name: Prepare Job
      #   run: |
      #     # Service Account for Job
      #     sudo kubectl create -f tools/test-rolebinding.yaml
      #     # Configmap will be witinig untill it is deleted, telling one Pod ended the Job
      #     sudo kubectl create configmap molecule-job-running --from-literal status=Started


      # - name: Start test Job
      #   run: |
      #     cat <<EOF | sudo kubectl apply -f -
      #     ---
      #     apiVersion: batch/v1
      #     kind: Job
      #     metadata:
      #       name: molecule
      #     spec:
      #       template:
      #         spec:
      #           serviceAccountName: molecule-kubevirt
      #           containers:
      #           - name: molecule
      #             image: molecule_kubevirt_${{ matrix.tox_env }}
      #             imagePullPolicy: IfNotPresent
      #             command: [ "/bin/bash", "-c", "--" ]
      #             args: ["tox -e ${{ matrix.tox_env }} -c /opt/molecule_kubevirt/tox.ini; kubectl create configmap molecule-result --from-literal exitCode=$? && kubectl delete configmap molecule-job-running"]
      #             env:
      #               - name: PYTEST_REQPASS
      #                 value: "2"
      #           restartPolicy: Never
      #       backoffLimit: 0
      #     EOF

      #     echo "Job launched"


      # - name: Wait for Job to end and log Pods in default namespace
      #   run: |
      #     # Wait for Job Pod to start
      #     sudo kubectl wait --for=condition=ready pods -l job-name=molecule --namespace default
      #     # FIXME : virtctl not working when detached => open issue/PR on kubevirt
      #     ( sudo kubectl wait --timeout=15m --for=condition=Ready pod -l kubevirt.io=virt-launcher && sudo script -e -c "virtctl console instance" | tee /tmp/virtcl.txt || true ) &
      #     # Kail sends any logs from default namespace both to stdout and a log file
      #     ( sudo kail -n default 2>&1 | tee /tmp/kail.log || true ) &
      #     # Wait for molecule Job to delete configmap and notify one Job Pod as ran till the end
      #     sudo kubectl wait --for delete --timeout=20m  configmap/molecule-job-running
      #     # Exit of github action is the one set by molecule job in config map result
      #     # FIXME not sure its working for exit code part
      #     exit $(sudo kubectl get configmap molecule-result -o "jsonpath={.data['exitCode']}")


      # FIXME : if always ?
      - name: Export logs
        if: always()
        run: |
          mkdir -p /tmp/kind/logs || true
          sleep 30;
          sudo kubectl get events > /tmp/kind/logs/events.txt || true
          sudo kubectl describe jobs > /tmp/kind/logs/jobs.txt || true
          sudo kubectl describe cm > /tmp/kind/logs/cm.txt || true
          cp /tmp/kail.log /tmp/kind/logs || true
          cp /tmp/describes.txt /tmp/kind/logs || true
          sudo  cp /tmp/virtcl.txt /tmp/kind/logs || true
          sudo dmesg > /tmp/kind/logs/dmesg.txt || true
          sudo kind export logs /tmp/kind/logs || true
          sudo journalctl | cat > /tmp/kind/logs/journalctl.txt || true
          sudo chown -R $USER:$USER /tmp/kind/logs || true


      - name: Upload logs
        if: always()
        uses: actions/upload-artifact@v2
        with:
          name: kind-logs-${{ env.JOB_NAME }}-${{ github.run_id }}
          path: /tmp/kind/logs
    needs:
      - validate_code
